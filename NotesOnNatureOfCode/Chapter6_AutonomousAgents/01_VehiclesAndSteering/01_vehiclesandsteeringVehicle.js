//////////////////////////////////////////////////////////////////////////////////////////////
//                   AUTONOMOUS AGENTS: VEHICLES AND STEERING (VEHICLE CLASS)
//////////////////////////////////////////////////////////////////////////////////////////////
// The Nature of Code (Daniel Shiffman) http://natureofcode.com

///////////////////////////////////////////////////////
/*  WHAT ARE AUTONOMOUS AGENTS
///////////////////////////////////////////////////////

    So far in this course, we have focused only on inanimate objects: lifeless shapes sitting
  on our screens that move when affected by forces. What if we could breathe life into those
  shapes? What if those shapes could live by their own rules? We will do this in the current
  chapter by developing autonomous agent.
  
    The term AUTONOMOUS AGENT generally refers to an entity that makes its own choices about
  how to act in its environment without any influence from a leader or global plan. For us,
  “acting” will mean moving. We will again use the concept of forces to move our actor around.
  However, in these contexts, the forces will be generated by the agent.

    Here are three properties of autonomous agents that we should keep in mind:

    • AUTONOMOUS AGENTS HAVE A LIMITED ABILITY TO PERCEIVE THEIR ENVIRONMENT

      A living being must be aware of its environment. In our code, we will use programming
    techniques that allow objects to store references to other objects, and therefore give
    them the ability to “perceive” their environment. However, it is important to remember
    that this ability is limited: In our P5 sketches, we are not going to make an all-knowing
    rectangle that flies around a window, aware of everything else in that window. Instead,
    we are going to create a shape that, for example, can only examine any other object within
    fifteen pixels of itself. This is consistent with autonomous agents in the real world. An
    insect, for example, may only be aware of the sights and smells that immediately surround
    it.

    • AUTONOMOUS AGENTS PROCESS INFORMATION FROM THEIR ENVIRONMENT AND CALCULATE AN ACTION

      This will be easy for us in our code, as the action is just a force. The environment might
    tell the agent that there’s a big scary-looking shark swimming right at it, and the action
    will be a powerful force in the opposite direction.

    • AN AUTONOMOUS AGENT HAS NOT LEADER

      This third principle is less important as we might want to design a system where it makes
    sense for a leader to command various entities. However, many of the examples included in
    this chapter do have no leader for an important reason. As we get to the end of this chapter
    and examine group behaviors, we will look at designing collections of autonomous agents that
    exhibit the properties of complex systems — intelligent and structured group dynamics that
    emerge not from a leader, but from the local interactions of the elements themselves.

    In the late 1980s, computer scientist Craig Reynolds (http://www.red3d.com/cwr/) developed
  algorithmic steering behaviors for animated characters. These behaviors allowed individual
  elements to navigate their digital environments in a “lifelike” manner with strategies for
  fleeing, wandering, arriving, pursuing, evading, etc. Used in the case of a single autonomous
  agent, these behaviors are fairly simple to understand and implement. In addition, by building
  a system of multiple characters that steer themselves according to simple, locally based rules,
  surprising levels of complexity emerge. The most famous example is Reynolds’s “boids” model for
  “flocking/swarming” behavior.
*/

///////////////////////////////////////////////////////
/*  VEHICLES
///////////////////////////////////////////////////////

    In our first example, we could start out with artificial simulations of ant and termite colonies.
  These would be fantastic demonstrations of systems of autonomous agents. (For more on this topic,
  I encourage you to read TURTLES, TERMITES, AND TRAFFIC JAMS BY MITCHEL RESNICK.) However, we want to
  begin by examining agent behaviors that build on the work we’ve done in the first five chapters of
  this book: modeling motion with vectors and driving motion with forces. Consequently, we are going
  to rename our Mover class, which then became our Particle class in chapter 4. In his 1999 paper
  “Steering Behaviors for Autonomous Characters,” Reynolds uses the word “vehicle” to describe his
  autonomous agents. We will therefore choose the name VEHICLE.

    Reynolds describes the motion of idealised vehicles (idealised because they exist not in the real
  world, with actual engineering) as the product of of three processes:

  • ACTION SELECTION: A vehicle has a goal (or goals) and can select an action (or a combination of
      actions) based on that goal. In other words, a vehicle takes a look at its environment and
      calculates an action based on a desire. Reynolds’s paper describes many goals and associated
      actions such as: seek a target, avoid an obstacle, and follow a path.

  • STEERING: Once an action has been selected, the vehicle has to calculate its next move. For us,
      the next move will be a force; more specifically, a steering force. Luckily, Reynolds has
      developed a simple steering force formula that we’ll use throughout the examples in this
      chapter: steering force = desired velocity - current velocity. 

  • LOCOMOTION: For the most part, we’re going to ignore this third process. In the case of fleeing
      zombies, the locomotion could be described as “left foot, right foot, left foot, right foot,
      as fast as you can”. However, in our P5 world, a rectangle or circle or triangle’s actual movement
      across a window is irrelevant given that it’s all an illusion in the first place. Nevertheless,
      this isn’t to say that you should ignore locomotion entirely. For example, you could choose to
      animate the motion of an object around a screen, adding spinning wheels, oscillating paddles,
      or shuffling legs.

    Ultimately, the most important process for us to consider is Action Selection. What are the
  elements of your system and what are their goals?
*/

///////////////////////////////////////////////////////
/*  THE STEERING FORCE
///////////////////////////////////////////////////////

    The first concept we will need to understand is the steering force. Consider the following scenario:
  A vehicle moving with velocity desires to seek a target. Its goal and subsequent action is to seek
  the target. If you think back to Chapter 2, you might make the target an attractor and apply a
  gravitational force that pulls the vehicle to the target. This would be a perfectly reasonable
  solution, but conceptually it’s not what we’re looking for. We don’t want the vehicle to be pushed
  towards its target. Instead, we are asking the vehicle to make an intelligent decision to steer
  towards the target based on its perception of its state and environment (i.e. how fast and in what
  direction is it currently moving). The vehicle should look at how it desires to move (a vector
  pointing to the target), compare that goal with how quickly it is currently moving (its velocity), and
  apply a force accordingly.

  steering force = desired velocity - current velocity

    How do we calculate desired velocity? Well, it is simple a vector that points from its current
  location to the target location. However, this isn’t particularly realistic. What if we have a very
  high-resolution window and the target is thousands of pixels away? Sure, the vehicle might desire to
  teleport itself instantly to the target location with a massive velocity, but this won’t make for an
  effective animation. What we really want to say is: "The vehicle desires to move towards the target
  at maximum speed". In other words, the vector should point from location to target and with a magnitude
  equal to maximum speed (i.e. the fastest the vehicle can go). Therefore, we need to make sure we add a
  variable to our Vehicle class that stores maximum speed (i.e. this.maxspeed). Then, in our calculated
  of desired velocity, we scale according to maximum speed. See the code inside the seek() function of
  this call for full details on the code.

    We’ve missed one last step. What sort of vehicle is this? Is it a super sleek race car with amazing
  handling? Our example code, as it stands, has no feature to account for this variability in steering
  ability. Steering ability can be controlled by limiting the magnitude of the steering force. Let’s call
  that limit the “maximum force” (or maxforce for short). This limiting of the steering force brings up an
  important point. We must always remember that we don't want our vehicle to get to the target as fast as
  possible. If that were the case, we would just say “location equals target”. Our goal, as Reynolds puts it,
  is to move the vehicle in a “lifelike and improvisational manner.” We’re trying to make it appear as if the
  vehicle is steering its way to the target, and so it’s up to us to play with the forces and variables of
  the system to simulate a given behavior. For example, a large maximum steering force would result in a very
  different path than a small one. One is not inherently better or worse than the other; it depends on your
  desired effect.
*/

// The "Vehicle" class
class Vehicle {
  constructor(x, y) {
    this.acceleration = createVector(0, 0);
    this.velocity = createVector(0, -2);
    this.position = createVector(x, y);
    this.maxspeed = 8; // Store maximum speed
    this.maxforce = 0.1; // State the maximum steering force
    this.r = 6;
  }

  // Method to update location
  update() {
    this.velocity.add(this.acceleration); // Update velocity
    this.velocity.limit(this.maxspeed); // Limit speed
    this.position.add(this.velocity); // Update location
    this.acceleration.mult(0); // Reset accelerationelertion to 0 each cycle
  }

  applyForce(force) {
    this.acceleration.add(force); // We could add mass here if we want A = F / M
  }

  ///////////////////////////////////////////////////////////////////
  // A method that calculates a steering force towards a target
  ///////////////////////////////////////////////////////////////////
  seek(target) {

    // Get the desired velocity (i.e. a vector pointing from the location to the target)
    var desired = p5.Vector.sub(target, this.position);

    // Scale the desired velocity to maximum speed
    desired.setMag(this.maxspeed);

    // Calculate steering force (i.e. desired velocity - current velocity)
    var steer = p5.Vector.sub(desired, this.velocity);

    // Limit the force
    steer.limit(this.maxforce); // Limit to maximum steering force

    // Apply the force
    this.applyForce(steer);
  }

  display() {
    // Draw a triangle rotated in the direction of velocity
    var theta = this.velocity.heading() + PI / 2;
    fill(127);
    stroke(200);
    strokeWeight(1);
    push();
    translate(this.position.x, this.position.y);
    rotate(theta);
    beginShape();
    vertex(0, -this.r * 2);
    vertex(-this.r, this.r * 2);
    vertex(this.r, this.r * 2);
    endShape(CLOSE);
    pop();
  }
}